{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from tifffile import imwrite, imsave\n",
    "import datetime\n",
    "from numba import jit, njit, prange\n",
    "from functools import partial\n",
    "import time \n",
    "import pandas as pd\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "import trackpy as tp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast implementation of the tiling, plane leveling, and segmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are efficient implementations of tiling, plane leveling, and segmentation using numba\n",
    "\n",
    "@partial(jit, nopython=True)\n",
    "def swap(x, t_args):\n",
    "    \"\"\"Executes the np transpose function in a way that numba will understand, there is a bug with how numba understands np.transpose and this is a workaround\"\"\"\n",
    "    return np.transpose(x, t_args)\n",
    "\n",
    "@njit\n",
    "def tile_image(imframe: np.ndarray, tilesize: tuple):\n",
    "    \"\"\"Returns an array of image tiles with shape (Y, X, n, m) where Y is the tile row number, X is the tile column\n",
    "    number, n is the tile pixel height and m is the tile pixel width\"\"\"\n",
    "    img_height, img_width = imframe.shape\n",
    "    tileheight, tilewidth = tilesize\n",
    "    imcopy = imframe.copy() #workaround for numba reshape not supporting non-contiguous arrays\n",
    "    tiled_array = imcopy.reshape(img_height // tileheight, tileheight, img_width // tilewidth, tilewidth)\n",
    "    out_array = swap(tiled_array,(0,2,1,3))\n",
    "    return out_array\n",
    "\n",
    "@njit\n",
    "def reform_image(tilearray: np.ndarray, originalsize: tuple):\n",
    "    \"\"\"Reforms an image from a tile array with shape (Y, X, n, m) where Y is the tile row number, X is the tile column\n",
    "    number, n is the tile pixel height and m is the tile pixel width.  Returns an image with the shape of the original imag\"\"\"\n",
    "    \n",
    "    reordered = swap(tilearray,(0,2,1,3))\n",
    "    contiguous = reordered.copy() #numba doesn't support numpy reshaping of non-congiguous arrays so you have to copy it as a workaround\n",
    "    reformed = contiguous.reshape(originalsize)\n",
    "    return reformed\n",
    "\n",
    "@njit\n",
    "def linalg_test(solvematrix, zmatrix):\n",
    "    coefs = np.linalg.lstsq(solvematrix, zmatrix)[0]\n",
    "    return coefs\n",
    "\n",
    "@njit\n",
    "def plane_level_njit(img: np.ndarray):\n",
    "    \"\"\"Takes a 2d image (numpy array), calculates the mean plane, and returns that 2d image after subtracting the\n",
    "    mean plane\"\"\"\n",
    "\n",
    "    \"\"\"Create x, y, and z (pixel intensity) arrays\"\"\"\n",
    "    dimensions = img.shape\n",
    "    totalpoints = dimensions[0] * dimensions[1]\n",
    "    xarray = np.linspace(0, totalpoints - 1, totalpoints) % dimensions[0]\n",
    "    yarray = np.linspace(0, dimensions[1] - 1, totalpoints)  # a sequence that makes y values that correspond to the z points\n",
    "    flatimg = img.flatten()+0.0\n",
    "\n",
    "    \"\"\"Calculate the best fit plane through the datapoints\"\"\"\n",
    "    cvals = xarray*0+1.0  #make the cvals floats\n",
    "\n",
    "    xyc = np.column_stack((xarray, yarray, cvals))\n",
    "    coefs = np.linalg.lstsq(xyc, flatimg)[0]  #njit and lstsq require all the datatypes to be the same\n",
    "\n",
    "    leveled_flat = flatimg-((coefs[0]*xarray+coefs[1]*yarray+coefs[2])-np.mean(flatimg))\n",
    "\n",
    "    final_img = leveled_flat.reshape(img.shape)\n",
    "    return final_img\n",
    "\n",
    "@njit\n",
    "def median_prominence_threshold(imgarray, prominence):\n",
    "    \"\"\"Takes an input array and thresholds it using median + prominence\"\"\"\n",
    "    brlevel = np.median(imgarray)\n",
    "    threshold = brlevel + prominence\n",
    "    thresholded = (imgarray > threshold)\n",
    "    \n",
    "    \n",
    "    return thresholded\n",
    "\n",
    "#This is the main function that levels and segments an image\n",
    "@njit(parallel=True)\n",
    "def batch_level_segment(image: np.array, tileshape: tuple, imageshape: tuple, threshold):\n",
    "    \"\"\"efficient numba implementation of a function that takes a 3d image as a np array, tiles it, levels it, \n",
    "    and segments it \"\"\"\n",
    "    segmented_timeseries = np.zeros(image.shape)\n",
    "\n",
    "    for frameid in range(image.shape[0]):\n",
    "        \n",
    "        frame = image[frameid,:,:]\n",
    "        tiles = tile_image(frame, tileshape)\n",
    "        segmented = np.zeros(tiles.shape)\n",
    "\n",
    "        for i in prange(tiles.shape[0]):\n",
    "            for j in prange(tiles.shape[1]):\n",
    "                tile = tiles[i,j,:,:]\n",
    "                leveltile = plane_level_njit(tile)\n",
    "                segmentedtile = median_prominence_threshold(leveltile,threshold)\n",
    "                segmented[i,j,:,:] = segmentedtile\n",
    "\n",
    "\n",
    "        reformed = reform_image(segmented, imageshape)\n",
    "        segmented_timeseries[frameid,:,:] = reformed.astype(np.uint8)\n",
    "        print(frameid)\n",
    "\n",
    "    return segmented_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an implementation that subtracts masks from the file, it is the same as the function defined in crop_and_norm.ipynb\n",
    "def mask_subtract(data: str, mask: str, outfile: str):\n",
    "    \"\"\"takes a numpy array and multiplies it buy a mask.  Data and mask must be the same dimensions, and mask must be valued 1-0.\"\"\"\n",
    "    image = imread(data)\n",
    "    print(image.shape, image.dtype)\n",
    "    original_dtype = image.dtype\n",
    "    mask = imread(str(mask))\n",
    "    print(mask.shape, mask.dtype)\n",
    "    #this should normalize the mask to 0-1.  \n",
    "    mask = (mask-np.min(mask))/(np.max(mask)-np.min(mask))\n",
    "    print(np.min(mask), np.max(mask))\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            for slice in range(image.shape[0]):\n",
    "                image[slice,:,:] = image[slice,:,:]*mask[:,:,0]\n",
    "        except:\n",
    "                for slice in range(image.shape[0]):\n",
    "                    image[slice,:,:] = image[slice,:,:]*mask[:,:]\n",
    "    except: \n",
    "        print(\"Mask/Image dimension mismatch, masking skipped\")\n",
    "\n",
    "    image = image.astype(original_dtype)\n",
    "    imsave(outfile, image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function finds particles from individual image frames by tracking connected groups of pixels between a minsize and maxsize\n",
    "def findparticles_3d_img(frames: np.array, minsize=5, maxsize = 200):\n",
    "    \"\"\"\n",
    "        This function takes a 3d image \"frames\" with the structure [frame, x, y]\n",
    "\n",
    "       Create a pandas dataframe, and then find the particles (regions) using skimage's label function.  Label connects\n",
    "       regions of the same integer value, i.e. segmented regions. In this dataframe, I also save the perimeter, filled fraction,\n",
    "       and the area.\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    for i in range(frames.shape[0]):\n",
    "        label_image = label(frames[i,:,:], background=0)\n",
    "        props = regionprops_table(label_image,properties=(\"centroid\", \"area\"))\n",
    "        framedata = pd.DataFrame(props)\n",
    "        framedata['frame'] = i\n",
    "        features = features.append(framedata)\n",
    "        print(datetime.datetime.now(), i)\n",
    "\n",
    "    filtered = features[features['area'] >= minsize]\n",
    "    filtered = filtered[filtered['area'] <= maxsize]\n",
    "  \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a hyperspectral image\n",
    "#image = imread('2-CrXAS-movie@577-5eV.tif')\n",
    "#image = imread('3-CrXAS-movie@577-5eV.tif')\n",
    "image = imread('/Users/apple/Sync/Research/NSLS Experiments 7-16-23/20230716_Ni5Cr/Oxidation XAS mapping/XAS_30um_2CA_1AN_570-584eV_0.2eV_step_Cr2p_oxidation2_region2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform leveling and segmentation of an image, defining the tile size, original image size, and threshold \n",
    "output = batch_level_segment(image ,(128,128), (1024,1024),200)\n",
    "segmented = output.astype(np.uint8)\n",
    "\n",
    "imsave(\"cr5_ox2_200.tif\",segmented)\n",
    "#imsave(\"mov3_median_8000.tif\",segmented)\n",
    "#imsave(\"mov2_median_8000.tif\", segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask the image after leveling and segmenting to avoid plane leveling artifacts at the mask edges\n",
    "masked = mask_subtract(\"mov2_median_8000.tif\", \"2nd_oxidation_mask.tif\", \"mov2_masked_median_8000.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the particles in the hyperspectral image and puts them into a .csv file \n",
    "#total = imread(\"mov2_masked_median_8000.tif\")\n",
    "#total= imread(\"/Users/apple/vscode/Research/Oxidation 3 results/median_8000_masked.tif\")\n",
    "total = imread(\"cr5_ox2_200.tif\")\n",
    "features = findparticles_3d_img(total, minsize=4, maxsize = 200)     #minsize of 5 for the crox particles, and 15 for the dark regions\n",
    "features.to_csv(\"cr5_ox2_200_minsize_4.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
